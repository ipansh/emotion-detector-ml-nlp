{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from numpy import array\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, Bidirectional\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = '/Users/ilya/Desktop/Computer-Science/Github/emotion-nlp-detector/dataset/'\n",
    "\n",
    "with open(os.path.join(path_name,'train.txt')) as f:\n",
    "    train_list = f.readlines()\n",
    "\n",
    "with open(os.path.join(path_name,'test.txt')) as f:\n",
    "    test_list = f.readlines()\n",
    "\n",
    "with open(os.path.join(path_name,'val.txt'))as f:\n",
    "    val_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canv...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion\n",
       "0  im feeling quite sad and sorry for myself but ...  sadness\n",
       "1  i feel like i am still looking at a blank canv...  sadness\n",
       "2                     i feel like a faithful servant     love\n",
       "3                  i am just feeling cranky and blue    anger\n",
       "4  i can have for a treat or if i am feeling festive      joy"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_list = val_list+test_list+train_list\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['sentence'] = [sentence.split(';')[0] for sentence in full_list]\n",
    "df['emotion'] = [sentence.split(';')[1].strip('\\n') for sentence in full_list]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>2373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>6761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>5797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surprise</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion  count\n",
       "0     anger   2709\n",
       "1      fear   2373\n",
       "2       joy   6761\n",
       "3      love   1641\n",
       "4   sadness   5797\n",
       "5  surprise    719"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('emotion').count().reset_index().rename(columns = {'sentence':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_string(item):\n",
    "    doc = nlp(item)\n",
    "    return ' '.join([token.lemma_ for token in doc if token.lemma_ != '-PRON-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 "
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "counter = 0\n",
    "\n",
    "for chunk in np.array_split(df, 20):\n",
    "    chunk['sentence'] = chunk['sentence'].apply(lambda x: lemmatize_string(x))\n",
    "    main_df = main_df.append(chunk)\n",
    "    counter = counter+1\n",
    "    print(counter, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(main_df['emotion'])\n",
    "labels = to_categorical(encoded_labels)\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Number of words in sentnce: 61\n"
     ]
    }
   ],
   "source": [
    "sorted_list = sorted([len(sentence.split(' ')) for sentence in main_df['sentence']], reverse = True)\n",
    "print('Max Number of words in sentnce: {}'.format(sorted_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode_dict = {0:'anger', 1:'fear', 2:'joy', 3:'love', 4:'sadness', 5:'surprise'}\n",
    "\n",
    "vocab_size = 1000\n",
    "sent_len = 62\n",
    "dim_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(main_df['sentence'])\n",
    "one_hot_rep = tokenizer.texts_to_sequences(main_df['sentence'])\n",
    "\n",
    "#one_hot_rep = [one_hot(sentence, vocab_size) for sentence in main_df['sentence']]\n",
    "padded_docs = pad_sequences(one_hot_rep, padding = 'pre', maxlen = sent_len)\n",
    "\n",
    "## original implementation\n",
    "#one_hot_rep = [one_hot(sentence, vocab_size) for sentence in main_df['sentence']]\n",
    "#padded_docs = pad_sequences(one_hot_rep, padding = 'pre', maxlen = sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(one_hot_rep[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tokenizer, 'tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = padded_docs[:15000]\n",
    "x_test = padded_docs[15000:]\n",
    "y_train = labels[:15000]\n",
    "y_test = labels[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 62, 100)           100000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 336,038\n",
      "Trainable params: 336,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, dim_num, input_length=sent_len))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "141/141 [==============================] - 45s 293ms/step - loss: 0.4657 - accuracy: 0.3375 - val_loss: 0.4032 - val_accuracy: 0.3372\n",
      "Epoch 2/15\n",
      "141/141 [==============================] - 35s 248ms/step - loss: 0.3766 - accuracy: 0.4575 - val_loss: 0.2867 - val_accuracy: 0.6322\n",
      "Epoch 3/15\n",
      "141/141 [==============================] - 39s 277ms/step - loss: 0.2273 - accuracy: 0.7353 - val_loss: 0.2005 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "141/141 [==============================] - 31s 223ms/step - loss: 0.1475 - accuracy: 0.8382 - val_loss: 0.1798 - val_accuracy: 0.7946\n",
      "Epoch 5/15\n",
      "141/141 [==============================] - 44s 314ms/step - loss: 0.1092 - accuracy: 0.8788 - val_loss: 0.1627 - val_accuracy: 0.8097\n",
      "Epoch 6/15\n",
      "141/141 [==============================] - 36s 254ms/step - loss: 0.0894 - accuracy: 0.9039 - val_loss: 0.1654 - val_accuracy: 0.8112\n",
      "Epoch 7/15\n",
      "141/141 [==============================] - 34s 239ms/step - loss: 0.0843 - accuracy: 0.9033 - val_loss: 0.1799 - val_accuracy: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a27a8d950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "\n",
    "# fit the model\n",
    "model.fit(x_train, y_train, epochs=15, verbose=1, validation_split = 0.7, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1532 - accuracy: 0.8222\n"
     ]
    }
   ],
   "source": [
    "classes = model.predict_classes(x_test)\n",
    "\n",
    "eval_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_count</th>\n",
       "      <th>correct_label_count</th>\n",
       "      <th>class_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surprise</td>\n",
       "      <td>172</td>\n",
       "      <td>90</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>393</td>\n",
       "      <td>272</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>691</td>\n",
       "      <td>524</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>628</td>\n",
       "      <td>482</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>1639</td>\n",
       "      <td>1420</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>1477</td>\n",
       "      <td>1323</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  label_count  correct_label_count  class_accuracy\n",
       "5  surprise          172                   90            0.52\n",
       "3      love          393                  272            0.69\n",
       "0     anger          691                  524            0.76\n",
       "1      fear          628                  482            0.77\n",
       "2       joy         1639                 1420            0.87\n",
       "4   sadness         1477                 1323            0.90"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame()\n",
    "val_df['actual_label'] = encoded_labels[15000:]\n",
    "val_df['pred_label'] = classes\n",
    "\n",
    "val_df.loc[:,'actual_label'] = [hot_encode_dict[label_code] for label_code in list(val_df['actual_label'])]\n",
    "val_df.loc[:,'pred_label'] = [hot_encode_dict[label_code] for label_code in list(val_df['pred_label'])]\n",
    "\n",
    "val_df = val_df.groupby('actual_label').count().reset_index().rename(columns = {'pred_label':'label_count','actual_label':'label'})\\\n",
    "    .merge(val_df[val_df['actual_label'] == val_df['pred_label']].groupby('actual_label').count().reset_index()\\\n",
    "        .rename(columns = {'pred_label':'correct_label_count','actual_label':'label'}), left_on = ['label'], right_on = ['label'])\n",
    "\n",
    "val_df.loc[:,'class_accuracy'] = round(val_df['correct_label_count']/val_df['label_count'],2)\n",
    "\n",
    "val_df.sort_values(by = 'class_accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = 'What an awesome day to deploy a real model with embeddings!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_rep = tokenizer.texts_to_sequences([test_sentence])\n",
    "padded_sent = pad_sequences(one_hot_rep, padding = 'pre', maxlen = sent_len)\n",
    "response = np.argmax(model.predict(padded_sent), axis=-1)[0]\n",
    "\n",
    "hot_encode_dict[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_rep = tokenizer.texts_to_sequences([test_sentence])\n",
    "padded_sent = pad_sequences(one_hot_rep, padding = 'pre', maxlen = sent_len)\n",
    "response = np.argmax(loaded_model.predict(padded_sent), axis=-1)[0]\n",
    "\n",
    "hot_encode_dict[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
